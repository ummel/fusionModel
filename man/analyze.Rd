% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/analyze.R
\name{analyze}
\alias{analyze}
\title{Analyze synthetic data}
\usage{
analyze(
  formula,
  implicates,
  donor.N,
  sample_weights = NULL,
  replicate_weights = NULL,
  static = NULL,
  by = NULL,
  var.scale = 4,
  cores = 1
)
}
\arguments{
\item{formula}{A formula describing the desired analysis. Example: \code{var1 ~ 1} requests mean and total if \code{var1} is numeric or proportions for individual levels if \code{var1} is a factor. Regression model formulas can be specified as in \code{\link[stats]{glm()}}.}

\item{implicates}{Data frame containing implicates of synthetic (fused) variables. Typically generated by \link{fuseM()}. The implicates should be row-stacked and identified by integer column "M".}

\item{donor.N}{Number of (un-weighted) observations in the original "donor" data used to generate the implicates.}

\item{sample_weights}{Vector of primary sampling weights.}

\item{replicate_weights}{Optional data frame where each column is a set of survey replicate weights. \code{nrow(replicate_weights)} should equal \code{length(sample_weights)}. If \code{NULL}, standard errors are calculated without using replicate weights.}

\item{static}{Optional data frame containing static (non-synthetic) variables that do not vary across implicates. These are variables either required by \code{formula} or \code{by}.}

\item{by}{Character. Optional column name(s) in \code{implicates} or \code{static} (typically factors) that collectively define the population subgroups across which the analysis will be performed. If \code{NULL}, analysis is performed on the whole sample.}

\item{var.scale}{Scalar by which to scale the standard variance in the presence of replicate weights. This is determined by the survey design. The default (\code{var.scale = 4}) is appropriate for both RECS and ACS.}

\item{cores}{Integer. Number of cores used. Only applicable on Unix systems.}
}
\value{
A tibble reporting analysis results, possibly across population subgroups defined in \code{by}. The returned quantities include:

\describe{
\item{estimate}{Point estimate. Mean of estimates across implicates.}
\item{std_error}{Pooled standard error of the point estimate.}
\item{lower_ci}{Lower bound of 95\% confidence interval.}
\item{upper_ci}{Upper bound of 95\% confidence interval.}
\item{statistic}{Test statistic; z-value for proportions and t-value otherwise.}
\item{pvalue}{p-value of the test statistic, rounded to five decimals.}
\item{degf}{Degrees of freedom (zero for proportions); \code{N - 1} if a single implicate provided and calculated according to Reiter (2003) otherwise.}
\item{nobs}{Mean number of observations per strata across implicates.}
}
}
\description{
Calculation of point estimates and associated standard errors for analyses using synthetic microdata. Can calculate means, totals, proportions, and linear regression coefficients, optionally performed across population subgroups.
}
\details{
At a minimum, the user must supply synthetic implicates (typically generated by \link{fuseM()}) and primary sampling weights. Inputs are checked for consistent dimensions.

If \code{implicates} contains only a single version of the data (see Examples), calculations proceed but with a warning to let user know that there is no variance across implicates.

Estimates and standard errors for the requested analysis are calculated separately for each implicate. The final point estimate is the mean estimate across implicates. The final standard error is the pooled SE across implicates, calculated using Reiter's pooling rules for partially synthetic data (Reiter 2003).

When replicate weights are provided, the standard errors of each implicate are calculated via the variance of estimates across replicates. Calculations leverage \code{\link[data.table]{data.table}} operations for speed and memory efficiency. The within-implicate variance is calculated around the point estimate (rather than around the mean of the replicates). This is equivalent to \code{mse = TRUE} in \code{\link[survey]{svrepdesign()}}. This seems to be the appropriate method for most surveys.

If replicate weights are NOT provided, the standard errors of each implicate are calculated using variance within the implicate. For means (and totals), the ratio variance approximation of Cochran (1977) is used, as this is known to be a good approximation of bootstrapped SE's for weighted means (Gatz and Smith 1995). For proportions, a generalization of the unweighted SE formula is used (\href{https://stats.stackexchange.com/questions/159204/how-to-calculate-the-standard-error-of-a-proportion-using-weighted-data}{see here}). For regression coefficients, the standard error is calculated by \code{\link[stats]{summary.glm()}}.
}
\examples{
# Build a fusion model using RECS microdata
fusion.vars <- c("electricity", "natural_gas", "aircon")
predictor.vars <- names(recs)[2:12]
fit <- train(data = recs, y = fusion.vars, x = predictor.vars)

# Generate 10 implicates of synthetic 'fusion.vars'
#  using original RECS data as the recipient
recipient <- recs
sim <- fuseM(data = recipient, train.object = fit, M = 10)
head(sim)

#---------

# Analyze simulated electricity consumption,
# by climate zone, without replicate weights
result1 <- analyze(formula = electricity ~ 1,
                  implicates = sim,
                  sample_weights = recipient$weight,
                  replicate_weights = NULL,
                  static = recipient,
                  by = "climate",
                  donor.N = nrow(recipient))

# Analyze simulated electricity consumption,
# by climate zone, WITH replicate weights
result2 <- analyze(formula = electricity ~ 1,
                   implicates = sim,
                   sample_weights = recipient$weight,
                   replicate_weights = recipient[startsWith(names(recipient), "rep_")],
                   static = recipient,
                   by = "climate",
                   donor.N = nrow(recipient))

# Helper function for comparison plots
pfun <- function(x, y) {plot(x, y); abline(0, 1, lty = 2)}

# Inclusion of replicate weights does not affect estimates, but it does
# increase standard errors considerably due to RECS small sample size
pfun(result1$estimate, result2$estimate)
pfun(result1$std_error, result2$std_error)

#---------

# Conduct the same analyses using the original RECS data
# This generates a warning, since only an (implicit) single implicate is provided
# Without replicate weights
orig1 <- analyze(formula = electricity ~ 1,
                implicates = recs,
                sample_weights = recs$weight,
                replicate_weights = NULL,
                static = recs,
                by = "climate",
                donor.N = nrow(recs))

# And WITH replicate weights
orig2 <- analyze(formula = electricity ~ 1,
                 implicates = recs,
                 sample_weights = recs$weight,
                 replicate_weights = recs[startsWith(names(recs), "rep_")],
                 static = recs,
                 by = "climate",
                 donor.N = nrow(recs))

# Comparison plots of the original and simulated results
pfun(orig1$estimate, result1$estimate)  # Estimates
pfun(orig1$std_error, result1$std_error)  # SE's without replicates
pfun(orig2$std_error, result2$std_error)  # SE's with replicates

# Formal comparison of original and simulated results
# using confidence interval overlap; see ?compare()
comp1 <- compare(orig1, result1)  # without replicates
summary(comp1$overlap)
comp2 <- compare(orig2, result2)  # with replicates
summary(comp2$overlap)

#---------

# Other examples of analyze() syntax and usage

# Proportions of air conditioning technologies, by race, with replicate weights
result <- analyze(formula = aircon ~ 1,
                  implicates = sim,
                  sample_weights = recipient$weight,
                  replicate_weights = select(recipient, starts_with("rep_")),
                  static = recipient,
                  by = "race",
                  donor.N = nrow(recipient))

# Linear regression, full sample, without replicate weights
result <- analyze(formula = electricity ~ income + aircon + climate,
                 implicates = sim,
                 sample_weights = recipient$weight,
                 replicate_weights = NULL,
                 static = recipient,
                 by = NULL,
                 donor.N = nrow(recipient))

# Natural gas means and totals, by heating technology and climate, with replicate weights
result <- analyze(formula = natural_gas ~ 1,
                  implicates = sim,
                  sample_weights = recipient$weight,
                  replicate_weights = select(recipient, starts_with("rep_")),
                  static = recipient,
                  by = c("heating", "climate"),
                  donor.N = nrow(recipient))

#---------

# Testing replicate weight calculations
# Confirm that analyze() can reproduce results from 'survey' package

# Create 'survey' package RECS survey design object
recs.design <- survey::svrepdesign(
  data = recs,
  weights = recs$weight,
  repweights = select(recs, starts_with("rep_")),
  type = "Fay",
  rho = 0.5,
  mse = TRUE
)

 # Perform checks for mean and total electricity, by climate
check1 <- survey::svyby(electricity ~ 1, by = recs$climate, recs.design, FUN = survey::svymean)
check2 <- survey::svyby(electricity ~ 1, by = recs$climate, recs.design, FUN = survey::svytotal)
test <- analyze(formula = electricity ~ 1,
                implicates = recs,
                sample_weights = recs$weight,
                replicate_weights = select(recs, starts_with("rep_")),
                by = "climate",
                donor.N = nrow(recs))

# Confirm that results are identical
all.equal(check1$electricity, filter(test, metric == "mean")$estimate)
all.equal(check1$se, filter(test, metric == "mean")$std_error)
all.equal(check2$electricity, filter(test, metric == "total")$estimate)
all.equal(check2$se, filter(test, metric == "total")$std_error)

}
\references{
Cochran, W. G. (1977). \emph{Sampling Techniques} (3rd Edition). Wiley, New York.

Gatz, Donald F., and Luther Smith. (1995). The Standard Error of a Weighted Mean Concentration — I. Bootstrapping vs Other Methods. \emph{Atmospheric Environment}, vol. 29, no. 11, 1185–1193.

Reiter, J.P. (2003). Inference for Partially Synthetic, Public Use Microdata Sets. \emph{Survey Methodology}, vol. 29, 181-189.
}
