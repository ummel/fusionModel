% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/analyze.R
\name{analyze}
\alias{analyze}
\title{Analyze synthetic data to calculate point estimates and uncertainty}
\usage{
analyze(
  formula,
  by,
  synthetic,
  static,
  donor.N,
  syn.N = nrow(static),
  var.scale = 4,
  cores = 1
)
}
\arguments{
\item{formula}{A formula expression describing the desired analysis. Example: \code{var1 ~ 1} requests mean and totals if \code{var1} is numeric or proportions if \code{var1} is a factor.}

\item{by}{Character. Column name(s) in \code{synthetic} or \code{static} (typically factors) that collectively define the population subgroups to analyze.}

\item{synthetic}{A data frame containing synthetic implicates, each implicate having the same number of rows as \code{static}, where the implicates are identified by integer column "M". Alternatively, a list of data frames containing synthetic implicates, each with the same number of rows as \code{static}. Typically generated by \link{fuseM}.}

\item{static}{Data frame containing static (non-synthetic) variables with the same number of rows as \code{synthetic}. These data are "static" since they do not vary across implicates. At a minimum, this must include a column named \code{"weight"} giving the primary sampling weights and at least two columns of replicate weights denoted \code{"rep_1"}, \code{"rep_2"}, etc.}

\item{donor.N}{Number of (un-weighted) observations in the original "donor" data used to generate the implicates.}

\item{syn.N}{Number of (un-weighted) observations in the "recipient" data. Usually \code{nrow(static)}, the default.}

\item{var.scale}{Value by which to scale the standard variance calculated across replicate weights. This is specified by the survey design. \code{var.scale = 4} (the default) for both RECS and ACS.}

\item{cores}{Integer. Number of cores used for parallel operations.}
}
\value{
A tibble reporting results for the \code{response} variable across population subgroups of \code{by}. The returned quantities are:

\describe{
\item{estimate}{Point estimate. Mean of estimates across the implicates.}
\item{std_error}{Pooled standard error of the point estimate.}
\item{lower_ci}{Lower bound of 95\% confidence interval.}
\item{upper_ci}{Upper bound of 95\% confidence interval.}
\item{degf}{Degrees of freedom of t-distribution if calculating custom confidence intervals.}
\item{nobs}{Mean number of observations per strata across the implicates.}
\item{rshare}{Share of total uncertainty that is attributable to variance across replicate weights (as opposed to variance across implicates).}
}
}
\description{
Calculation of point estimates and associated standard errors for analyses using synthetic microdata. Analysis is currently limited to means, totals, and proportions, (optionally) calculated for population subgroups. Plan to extend to regression model coefficients and custom microsimulation analyses in future. User must supply a list of synthetic implicates (typically generated by \link{fuseM}) and "static" (non-synthetic) variables required by the analysis, including sampling and replicate weights.
}
\details{
Argument \code{"static"} must include both sample and replicate weights. The total uncertainty of any given analysis results from the combination of uncertainty across replicate weights and uncertainty across synthetic implicates. That is, uncertainty concerning the household weights in the recipient survey plus uncertainty concerning the value each household takes with respect to a particular variable (i.e. model uncertainty).

The requested analysis is performed separately for each implicate. The final point estimate is the mean estimate across implicates. The final standard error is the pooled SE's calculated via the variance across replicate weights. Pooled SE's are calculated using Reiter's pooling rules for partially synthetic data (Reiter, 2003). The estimate and standard error of each implicate is calculated using the provided observation weights. Calculations utilize custom code leveraging \code{\link[data.table]{data.table}} operatons for speed and memory efficiency.

The within-implicate variance is calculated around the point estimate (rather than around the mean of the replicates). This is equivalent to \code{mse = TRUE} in \code{\link[survey]{svrepdesign}}. This seems to be the appropriate method for most surveys.
}
\examples{
# Build a fusion model using RECS microdata
fusion.vars <- c("electricity", "natural_gas", "aircon")
predictor.vars <- names(recs)[2:12]
fit <- train(data = recs, y = fusion.vars, x = predictor.vars)

# Generate 5 implicates of synthetic 'fusion.vars',
#  using original RECS data as the recipient
recipient <- recs[predictor.vars]
sim <- fuseM(data = recipient, train.object = fit, M = 5)

# Analyze electricity consumption, by climate zone
result <- analyze(formula = electricity ~ 1,
                  by = "climate",
                  synthetic = sim,
                  static = recs,
                  donor.N = nrow(recs))

# Analyze air conditioning technology, by race
result <- analyze(formula = aircon ~ 1,
                  by = "race",
                  synthetic = sim,
                  static = recs,
                  donor.N = nrow(recs))

# Analyze natural gas consumption across whole sample
result <- analyze(formula = natural_gas ~ 1,
                  synthetic = sim,
                  static = recs,
                  donor.N = nrow(recs))

# If a single implicate is provided, calculation
#  proceeds but with a useful warning
result <- analyze(formula = natural_gas ~ 1,
                  synthetic = sim[1],
                  static = recs,
                  donor.N = nrow(recs))

#----------

# Validation of internal calculations
# If single implicate is provided, the results should
#  match standard replicate weight calculations

# Analyze using just a single implicate
result <- analyze(
 formula = electricity ~ 1,
 by = "climate",
 synthetic = sim[1],
 static = recs,
 donor.N = nrow(recs)
) \%>\%
filter(metric == "mean")

# Result of standard replicate weight calculation,
#  as implemented within "survey" package
recs.design <- survey::svrepdesign(
 data = cbind(recipient, sim[[1]]),
 weights = recs$weight,
 repweights = select(recs, starts_with("rep_")),
 type = "Fay",
 rho = 0.5,
 mse = TRUE
)
check <- survey::svyby(
 formula = electricity ~ 1,
 by = ~ climate,
 FUN = survey::svymean,
 design = recs.design
)

# Compare 'result' with 'check'
all.equal(result$estimate, check$electricity)
all.equal(result$std_error, check$se)
}
\references{
Reiter, J.P. (2003). Inference for Partially Synthetic,
Public Use Microdata Sets. \emph{Survey Methodology}, \bold{29}, 181-189.
}
