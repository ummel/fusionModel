#' Fuse variables to a recipient dataset
#'
#' @description
#' Fuse variables to a recipient dataset using a .fsn model produced by \link{train} using conditional distribution matching. \code{fuseM()} provides a convenience wrapper for generating multiple implicates. Output of \code{fuseM()} can be passed to \code{analyze()}.
#'
#' @param data Data frame. Recipient dataset. All categorical variables should be factors and ordered whenever possible. Data types and levels are strictly validated against predictor variables defined in \code{model}.
#' @param file Character. Path to fusion model file (.fsn) generated by successful call to \link{train}.
#' @param k Integer. Number of nearest neighbors to identify among the donor observations.
#' @param max_dist Numeric. Controls the maximum allowable distance when identifying up to \code{k} nearest neighbors. \code{max_dist = 0} (default) means no distance restriction is applied.
#' @param idw Logical. Should inverse distance weighting be used when randomly selecting a donor observation from the \code{k} nearest neighbors?
#' @param ... Arguments passed to \code{fuse()}.
#' @param M Integer. Number of implicates to simulate.
#' @param cores Integer. Number of cores used. Only applicable on Unix systems.
#'
#' @details For each record in \code{data}, the predicted conditional distribution values are used to identify the \code{k} most-similar observations in the original donor data along the same dimensions. One of the \code{k} nearest neighbors is randomly selected to donate its observed/"real" response value for the fusion variable(s) in question. The random selection uses inverse distance weighting if \code{idw = TRUE}.
#' @details The \code{max_dist} value is a relative scaling factor. The search radius passed to \code{\link[RANN]{nn2}} is \code{max_dist * medDist}, where \code{medDist} is the median pairwise distance calculated among all of the donor observations. This approach allows \code{max_dist} to adjust the search radius in a consistent way across all fusion variables/blocks.
#'
#' @return For \code{fuse()}, a data frame with same number of rows as \code{data} and one column for each synthetic fusion variable. The order of the columns reflects the order in which they where fused.
#' @return For \code{fuseM()}, a data frame with number of rows equal to \code{M * nrow(data)}. Integer column ".M" indicates implicate assignment of each observation. Note that the ordering of recipient observations is consistent within implicates, so do not change the row order if using with \code{analyze()}.
#'
#' @examples
#' # Build a fusion model using RECS microdata
#' # Note that "test_model.fsn" will be written to working directory
#' ?recs
#' fusion.vars <- c("electricity", "natural_gas", "aircon")
#' predictor.vars <- names(recs)[2:12]
#' train(data = recs, y = fusion.vars, x = predictor.vars, file = "test_model.fsn")
#'
#' # Generate single implicate of synthetic 'fusion.vars',
#' #  using original RECS data as the recipient
#' recipient <- recs[predictor.vars]
#' sim <- fuse(data = recipient, file = "test_model.fsn")
#' head(sim)
#'
#' # Calling fuse() again produces different results
#' sim <- fuse(data = recipient, file = "test_model.fsn")
#' head(sim)
#'
#' # Generate multiple implicates via fuseM()
#' # This can be passed to 'implicates' argument in ?analyze()
#' sim <- fuseM(data = recipient, file = "test_model.fsn", M = 5)
#' head(sim)
#' table(sim$M)
#' @export

#---------------------

# Manual testing
#
# library(fusionModel)
# library(lightgbm)
# library(partykit)
# source("R/utils.R")
# #Example inputs
# data <- subset(recs, select = c(weight, division, urban_rural, climate, income, age, race, hh_size, televisions))
# file <- "fusion_model_test.fsn"
# idw <- TRUE
# k <- 10

#---------------------

fuse <- function(data,
                 file,
                 k = 5,
                 max_dist = 0,
                 idw = FALSE) {

  stopifnot(exprs = {
    is.data.frame(data)
    file.exists(file) & endsWith(file, ".fsn")
    k > 0 & k %% 1 == 0
    max_dist >= 0
    is.logical(idw)
  })

  if (is.data.table(data)) data <- as.data.frame(data)

  # Temporary directory to unzip to
  td <- tempfile()
  dir.create(td)

  # Names of files within the .fsn object
  fsn.files <- zip::zip_list(file)
  pfixes <- sort(unique(dirname(fsn.files$filename)))
  pfixes <- pfixes[pfixes != "."]

  # Load model metadata
  zip::unzip(zipfile = file, files = "metadata.rds", exdir = td)
  meta <- readRDS(file.path(td, "metadata.rds"))

  # Names, order, and 'blocks' of response variables
  yord <- meta$yorder

  # Check that necessary predictor variables are present
  xvars <- names(meta$xclass)
  miss <- setdiff(xvars, names(data))
  if (length(miss) > 0) stop("The following predictor variables are missing from 'data':\n", paste(miss, collapse = ", "))

  # Restrict 'data' to 'xvars'
  data <- data[xvars]

  # Check for appropriate class/type of predictor variables
  xclass <- meta$xclass
  xtest <- lapply(data, class)
  miss <- !map2_lgl(xclass, xtest, sameClass)
  if (any(miss)) stop("Incompatible data type for the following predictor variables:\n", paste(names(miss)[miss], collapse = ", "))

  # Check for appropriate levels of factor predictor variables
  xlevels <- meta$xlevels
  xtest <- lapply(subset(data, select = names(xlevels)), levels)
  miss <- !map2_lgl(xlevels, xtest, identical)
  if (any(miss)) stop("Incompatible levels for the following predictor variables\n", paste(names(miss)[miss], collapse = ", "))

  # Detect and impute any missing values in 'data'
  na.cols <- names(which(sapply(data, anyNA)))
  if (length(na.cols) > 0) {
    cat("Missing values imputed for the following variable(s):\n", paste(na.cols, collapse = ", "), "\n")
    for (j in na.cols) {
      x <- data[[j]]
      ind <- is.na(x)
      data[ind, j] <-  imputationValue(x, ind)
    }
  }

  # Coerce 'data' to sparse numeric matrix for use with LightGBM
  dmat <- tomat(data)

  #-----

  cat("Fusing donor variables to recipient...\n")

  for (i in 1:length(pfixes)) {

    v <- meta$yorder[[i]]
    block <- length(v) > 1

    # LightGBM predictor variables
    xv <- meta$xlist.lgb[[i]]

    # Unzip the lightGBM model(s) to temp directory
    mods <- grep(pattern = glob2rx(paste0(pfixes[i], "*.txt")), x = fsn.files$filename, value = TRUE)
    zip::unzip(zipfile = file, files = mods, exdir = td)

    # Row indices where to generate predictions
    # Modified, if necessary, is next code chunk when single continuous variables has a zero model
    zind <- rep(FALSE, nrow(dmat))

    #---

    # Simulate zero values for case of single continuous variable
    if (!block & meta$ytype[v[[1]]] == "continuous") {
      m <- grep("z\\.txt$", mods, value = TRUE)
      if (length(m)) {
        mod <- lightgbm::lgb.load(filename = file.path(td, m))
        p <- predict(object = mod, data = dmat[, xv], reshape = TRUE)
        zind <- p > runif(n = nrow(dmat)) # Row indices where a zero is randomly simulated (TRUE for a zero)
      }
      mods <- setdiff(mods, m)
    }

    #---

    # Load and make predictions for each model
    # This should be made more efficient...
    # NOTE: NEEDS TO HANDLE BINARY
    pred <- data.table()
    for (m in mods) {
      y <- sub("_[^_]+$", "", basename(m))
      n <- sub(".txt", "", sub(paste0(y, "_"), "", basename(m), fixed = TRUE), fixed = TRUE)
      q <- substring(n, 1, 1) == "q"
      z <- substring(n, 1, 1) == "z"
      mod <- lightgbm::lgb.load(filename = file.path(td, m))
      p <- predict(object = mod, data = dmat[!zind, xv], reshape = TRUE)
      if (!is.matrix(p)) p <- matrix(p)
      p <- as.data.table(p)
      set(pred, i = NULL, j = paste0(y, "_", n, if (q | z) NULL else 1:ncol(p)), value = p)
      rm(p)
    }

    #---

    # Apply normalization, as necessary, to recipient conditional values
    norm.vars <- intersect(names(pred), names(meta$ycenter[[i]]))
    for (j in norm.vars) {
      ncenter <- meta$ycenter[[i]][j]
      nscale <- meta$yscale[[i]][j]
      if (nscale == 0) {
        set(pred, i = NULL, j = j, value = NULL)
      } else {
        val <- normalize(pred[[j]], center = ncenter, scale = nscale)
        set(pred, i = NULL, j = j, value = val)
      }
    }

    #---

    # Simulate values for case of single categorical variable
    if (!block & meta$ytype[v[[1]]] != "continuous") {
      ptile <- runif(n = nrow(pred))
      S <- if (ncol(pred) > 1) {
        for (j in 2:ncol(pred)) set(pred, i = NULL, j = j, value = pred[[j - 1]] + pred[[j]])
        for (j in 1:ncol(pred)) set(pred, i = NULL, j = j, value = ptile > pred[[j]])
        rowSums(pred)  # First level receives value of zero
      } else {
        pred[[1]] > ptile  # The binary case
      }
    }

    #---

    if (block | meta$ytype[[v[1]]] == "continuous") {

      # Get the donor conditional prediction and response variables
      x <- paste0(pfixes[i], "/donor.fst")
      zip::unzip(zipfile = file, files = x, exdir = td)
      dpred <- fst::read_fst(file.path(td, x), as.data.table = TRUE, columns = colnames(pred))
      dresp <- fst::read_fst(file.path(td, x), as.data.table = TRUE, columns = v)
      setcolorder(pred, names(dpred))

      # Apply the column weights to 'pred'
      for (j in names(pred)) set(pred, i = NULL, j = j, value = pred[[j]] * meta$colweight[[i]][[j]])

      #----

      # Perform k-nearest-neighbor search
      nn <- RANN::nn2(data = dpred,
                      query = pred,
                      k = k,
                      searchtype = ifelse(max_dist == 0, "standard", "radius"),
                      radius = meta$meddist[i] * max_dist,
                      eps = 0.1)

      # Apply potential 'fix up' for cases where there is no nearest neighbor within the search radius
      if (max_dist > 0) {
        fix <- which(nn$nn.idx[, 1] == 0)
        if (length(fix) > 0) {
          nn.fix <- RANN::nn2(data = dpred,
                              query = pred[fix, ],
                              k = 1,
                              searchtype = "standard",
                              eps = 0.1)
          nn$nn.idx[fix, 1] <- nn.fix$nn.idx
          nn$nn.dists[fix, 1] <- nn.fix$nn.dists
          rm(fix, nn.fix)
        }
      }

      #----

      # Randomly select observation from the donor
      # Option for inverse-distance weighted
      if (idw) {
        nn$nn.dists[nn$nn.idx == 0] <- NA
        p <- 1 / nn$nn.dists
        p[is.infinite(p)] <- min(p)  # Prevent infinite inverse distance
        p <- p / rowSums(p, na.rm = TRUE)
        for (j in 2:ncol(p)) p[, j] <- p[, j - 1] + p[, j]
        ptile <- runif(n = nrow(p))
        S <- rowSums(ptile > p, na.rm = TRUE) + 1L
      } else {
        S <- sample.int(n = k, size = nrow(pred), replace = TRUE)
      }

      # Simulated values
      ind <- nn$nn.idx[cbind(1:nrow(nn$nn.idx), S)]
      S <- dresp[ind, ]

      # If zeros are simulated separately, integrate them into 'S'
      if (any(zind)) {
        out <- data.table(rep(0, nrow(dmat)))
        set(out, i = which(!zind), j = "V1", value = S)
        S <- out
      }

    }

    # Add the simulated values to 'dmat' prior to next iteration
    S <- tomat(S)
    colnames(S) <- v
    dmat <- cbind(dmat, S)
    rm(S, pred)

  }

  unlink(td)

  #---

  # Convert 'dmat' to desired output
  sim <- dmat[, unlist(yord)]
  sim <- data.table(as.matrix(sim))

  # Ensure simulated variables are correct data type with appropriate labels/levels
  for (v in names(sim)) {
    yclass <- meta$yclass[[v]]
    if ("factor" %in% yclass) {
      lev <- meta$ylevels[[v]]
      set(sim, i = NULL, j = v, value = factor(lev[sim[[v]] + 1], levels = lev, ordered = "ordered" %in% yclass))
    }
    if ("logical" %in% yclass) set(sim, i = NULL, j = v, value = as.logical(sim[[v]]))
    if ("integer" %in% yclass)  set(sim, i = NULL, j = v, value = as.integer(sim[[v]]))
  }

  return(sim)

}

#------------------------------

# Fuse multiple implicates
#' @rdname fuse
#' @export
fuseM <- function(..., M, fun = fuse, cores = 1) {
  stopifnot({
    M >= 1 & M %% 1 == 0
    cores > 0 & cores %% 1 == 0
  })
  pbapply::pblapply(1:M, function(i) {
    fun(...)
  }, cl = cores) %>%
    bind_rows(.id = "M") %>%
    mutate(M = as.integer(M))
}
