#' Generate output files resulting from fusion
#'
#' @description
#' Handles all operations needed to "do fusion" using input files generated by a successful call to \code{fusionInput}. Trains a fusion model, generates internal validation results, and then simulates multiple implicates for recipient microdata.
#'
#' @param input Character. Path to directory containing files created by \code{fusionInput}.
#' @param output Character. Optional path to directory where output files will be saved. If \code{output = NULL} (default), the output directory is automatically constructed from \code{input}.
#' @param M Integer. Desired number of fusion implicates. If \code{M = NULL} (default) it is internally set to 40 or, if \code{test_mode = TRUE}, 2 implicates.
#' @param note Character. Optional note supplied by user. Inserted in the log file for reference.
#' @param test_mode Logical. If \code{test_mode = TRUE} (default), the result files are always saved within a "/fusion_" directory in `output` (possibly created); faster hyperparameters are used for \code{\link[fusionModel]{train}}; and the internal validation step is skipped by default.
#' @param validation Logical or integer. Controls execution of internal validation (Steps 3 and 4). If `validation = 0` or `FALSE`, neither step is performed (default when `test_mode = TRUE`). If `1`, only Step 3. If `2` or `TRUE`, both Steps 3 and 4.
#' @param ncores Integer. Number of physical CPU cores used for parallel computation.
#' @param margin Numeric. Passed to same argument in \code{\link[fusionModel]{fuse}}.
#' @param ... Optional, non-default arguments passed to \code{\link[fusionModel]{train}}. For example, \code{fork = TRUE} to enable forked parallel processing.
#'
#' @details The function checks arguments and determines the file path to the appropriate `output` directory (creating it if necessary). The output files are always placed within the appropriate directory hierarchy, based on the donor and recipient information detected in the \code{input} file names. In practice, \code{output} need only be specified if working in an environment where the output files need to located somewhere different from the input files.
#'
#' The function executes the following steps:
#' 1. **Load training data inputs**. Loads donor training microdata and results of \code{\link[fusionModel]{prepXY}}.
#' 1. **Run fusionModel::train()**. Calls \code{\link[fusionModel]{train}} using sensible defaults and hyperparameters. If \code{test_mode = TRUE}, the hyperparameters are designed to do a fast/rough-and-ready model training.
#' 1. **Fuse onto training data for internal validation**. Optional step (see `validation` argument). Fuses multiple implicates to original donor training data using \code{\link[fusionModel]{fuse}}. Results saved to disk.
#' 1. **Run fusionModel::validate()**. Optional step (see `validation` argument). Passes previous step's results to \code{\link[fusionModel]{validate}}. Results saved to disk.
#' 1. **Fuse onto prediction data**. Fuses multiple implicates to supplied input prediction data using \code{\link[fusionModel]{fuse}}. Results saved to disk.
#' 1. **fusionOutput() is finished!** Upon completion, a log file named \code{"outputlog.txt"} is written to \code{output} for reference.
#'
#' @return Saves resulting `output` data files to appropriate local directory. Also saves a .txt log file alongside data files that records console output from \code{fusionOutput}.
#'
#' @examples
#' # Since 'test_mode = TRUE' by default, this will affect files in local '/fusion_' directory
#' dir <- fusionInput(donor = "RECS_2015",
#'                    recipient = "ACS_2015",
#'                    respondent = "household",
#'                    fuse = c("btung", "btuel", "cooltype"),
#'                    force = c("moneypy", "householder_race", "education", "nhsldmem", "kownrent", "recs_division"),
#'                    note = "Hello world. Reminder: running in test mode by default.")
#'
#' # List files in the /input directory
#' list.files(dir)
#'
#' # Using default settings
#' out <- fusionOutput(input = dir)
#' list.files(out)
#'
#' @export
# @noRd

#-----

# TESTING
# library(tidyverse)
# library(data.table)
# source("R/utils.R")
#
# donor = "RECS_2020"
# acs_year = 2015
# respondent = "household"
# fusion_vars <- c("aircond", "scaleb", "btuel")
# M <- 1
# note = NULL
# test_mode = TRUE
# validation = TRUE
# ncores = getOption("fusionData.cores")
# margin = 2

#-----

# Dummy respondent location data for testing
# geo <- fst::read_fst("geo-processed/concordance/geo_concordance.fst")
# donor = fst::read_fst("fusion_/RECS/2020/2015/RECS_2020_2015_H_donor.fst")
# temp <- geo %>%
#   select(state, county10, tract10) %>%
#   distinct() %>%
#   slice_sample(n = nrow(donor))
# rlocation <- data.frame(hid = donor$hid)
# rlocation <- cbind(rlocation, temp)
# rlocation <- slice_sample(rlocation, prop = 0.95)

# fusionOutput(donor = "RECS_2020",
#              respondent = "H",
#              acs_year = 2015,
#              fusion_vars = c("aircond", "scaleb", "btuel"),
#              fsn = "fusion_/RECS/2020/2015/RECS_2020_2015_H_model.fsn",
#              rlocation = rlocation)

#-----

fusionOutput <- function(donor,
                         respondent,
                         acs_year,
                         fusion_vars,
                         M = 1,
                         fsn = NULL,
                         rlocation = NULL,
                         note = NULL,
                         test_mode = TRUE,
                         validation = TRUE,
                         ncores = 1,
                         margin = 2,
                         ...) {

  tstart <- Sys.time()

  # Check validity of the working directory path
  # Checks if "/fusionData" is part of the path, as this is required
  b <- strsplit(full.path(getwd()), .Platform$file.sep, fixed = TRUE)[[1]]
  i <- which(b == "fusionData")
  if (length(i) == 0) stop("'/fusionData' is not part of the working directory path; this is required.")
  dir <- paste(b[1:i], collapse = .Platform$file.sep)

  # Get path to the fusion file directory
  donor <- strsplit(donor, "_", fixed = TRUE)[[1]]
  dir <- file.path(dir, ifelse(test_mode, "fusion_", "fusion"), donor[1], donor[2], acs_year)

  # Check input arguments
  respondent <- substring(toupper(respondent), 1, 1)
  stopifnot({
    respondent %in% c("H", "P")
    is.character(fusion_vars) | is.list(fusion_vars)
    M > 0 & M %% 1 == 0
    is.null(fsn) | is.character(fsn)
    is.null(rlocation) | is.data.frame(rlocation)
    is.null(note) | is.character(note)
    is.logical(test_mode)
    is.logical(validation)
    ncores > 0 & ncores %% 1 == 0
    is.numeric(margin)
  })

  # Check validity of the 'fusion_vars' argument
  fvars <- unlist(fusion_vars)
  if (anyDuplicated(fvars)) stop("Duplicate fusion variables provided (must be unique)")

  # Check validity of the 'fsn' argument, if present
  if (is.character(fsn)) {
    stopifnot({
      endsWith(fsn, ".fsn")
      file.exists(fsn)
    })
  }

  # # Construct the file path 'stub' for the output files
  # stub <- if (is.null(output)) {
  #   b <- strsplit(input, .Platform$file.sep, fixed = TRUE)[[1]]
  #   i <- which(b == "fusionData")
  #   if (length(i) == 0) {
  #     input
  #   } else {
  #     paste(b[1:i], collapse = .Platform$file.sep)
  #   }
  # } else {
  #   if (!dir.exists(output)) stop("'output' directory does not exist.")
  #   full.path(output)
  # }

  # Set number of implicates automatically, if not specified
  #if (is.null(M)) M <- ifelse(test_mode, 2, 30)

  # Create log file
  log.temp <- tempfile()
  log.txt <- file(log.temp, open = "wt")
  sink(log.txt, split = TRUE, type = "output")

  # Detect if 'fork = TRUE' is passed in the optional ... arguments
  # In this case, we need to turn off data.table and fst multi-threaded until after train() has executed
  #temp <- list(...)
  #fork <- if ("fork" %in% names(temp)) temp$fork else FALSE

  # Set cores for 'fst' and 'data.table' packages to use
  # fork <- FALSE ## TEMP!
  # data.table::setDTthreads(ifelse(fork, 1L, ncores))
  # fst::threads_fst(ifelse(fork, 1L, ncores))
  data.table::setDTthreads(ncores)
  fst::threads_fst(ncores)

  #-----

  # Report initial messages to console and log
  # The try() wrapper for fusionData is to allow case of running fusionModel::fusionOutput() on a server
  cat(format(tstart, usetz = TRUE), "\n")
  cat(R.version.string, "\n")
  cat("Platform:", R.Version()$platform, "\n")
  cat("fusionModel v", as.character(utils::packageVersion("fusionModel")), "\n\n", sep = "")

  # Print the original function arguments
  # Excludes 'note', if present, since it is printed separately to log, below
  print(match.call.defaults(exclude = if (is.null(note)) NULL else "note"))
  cat("\n")

  # Report the fusion directory or fail with error message
  if (dir.exists(dir)) {
    cat("The fusion directory is:\n", dir, "\n\n")
  } else {
    stop("Requested fusion directory does not exist. Input files not located at: ", dir)
  }

  # TEMP
  # Print message indicating 'test_mode' value
  cat("fusionOutput() is running in", ifelse(test_mode, "TEST", "PRODUCTION"), "mode.\n")

  # Write 'note' argument to log file (and console), if requested
  if (!is.null(note)) cat("User-supplied note:\n", note, "\n\n")

  #-----

  # Check for presence of training dataset
  tfile <- list.files(dir, paste0(respondent, "_donor\\.fst$"), full.names = TRUE)
  if (length(tfile) == 0) stop("Cannot locate 'donor.fst' file at: ", tfile)
  if (length(tfile) > 1) stop("Located more than one valid 'donor.fst' file...")

  # RETAIN?
  # Check for presence of prepXY() results
  # pfile <- sub("donor.fst$", "prep.rds", tfile)
  # if (length(pfile) == 0) stop("Cannot locate 'prep.rds' file in 'input'")
  # if (length(pfile) > 1) stop("There is more than one 'prep.rds' file in 'input'...")

  # Check for presence of ACS prediction dataset
  pfile <- sub("donor.fst$", "recipient.fst", tfile)
  if (length(pfile) == 0) stop("Cannot locate 'recipient.fst' file at: ", pfile)
  if (length(pfile) > 1) stop("Located more than one 'recipient.fst' file...")

  # Check for presence of donor processed microdata
  dfile <- list.files(path = "survey-processed", pattern = paste(c(donor, respondent, "processed.fst"), collapse = "_"), recursive = TRUE, full.names = TRUE)
  dfile <- full.path(dfile)
  if (length(dfile) == 0) stop("Cannot locate donor processed microdata in /survey-processed")
  if (length(dfile) > 1) stop("There is more than one valid donor processed microdata in /survey-processed")

  # Check for presence of 'geo_predictors.fst' file
  gfile <- full.path("geo-processed/geo_predictors.fst")
  if (length(gfile) == 0) stop("Cannot locate 'geo_predictors.fst' file")
  if (length(gfile) > 1) stop("There is more than one 'geo_predictors.fst' file in /geo-processed")

  # Construct full output path for results files and create the directory if necessary
  # dir <- dirname(file.path(stub, ifelse(test_mode, "fusion_", "fusion"), gsub("_", .Platform$file.sep, basename(tfile), fixed = TRUE)))
  # dir <- file.path(dir, "output")
  # cat("Result files will be saved to:\n", dir, "\n\n")
  # if (dir.exists(dir)) {
  #   cat("The local /output directory already exists.\n")
  # } else {
  #   dir.create(dir, recursive = TRUE)
  #   cat("The local /output directory was created.\n")
  # }

  # Update 'stub' used for output files
  stub <- file.path(dir, sub("donor.fst", "", basename(tfile), fixed = TRUE))

  #-----

  cat("\n|=== Load training data inputs ===|\n\n")

  # Load the training data - TO DO: ADD fusion variables via merge with processed donor microdata
  cat("Loading donor microdata:", basename(tfile), "\n")
  train.data <- fst::read_fst(tfile, as.data.table = TRUE)
  hvars <- grep("__", names(train.data), fixed = TRUE, value = TRUE)  # Harmonized predictor variables

  # If respondent locations are provided, replace the imputed state and PUMA with the known values
  if (is.data.frame(rlocation)) {
    cat("Updating donor imputed respondent location with known/disclosed location\n")
    geo <- fst::read_fst("geo-processed/concordance/geo_concordance.fst")
    rlocation <- geo %>%
      select(state, puma10, any_of(names(rlocation))) %>%
      distinct() %>%
      inner_join(rlocation) %>%
      select(hid, state, puma10) %>%
      filter(hid %in% as.character(train.data$hid)) %>%
      na.omit()

    # Update the state and PUMA, when possible, using known respondent locations
    if (nrow(rlocation) > 0) {
      N0 <- nrow(train.data)
      pct <- 100 * signif(nrow(rlocation) / nrow(train.data), 3)
      cat("Known location provided for ", nrow(rlocation), " donor respondents (", pct, "% of households)\n", sep = "")
      train.data <- train.data %>%
        mutate_at(vars(state, puma10), as.character) %>%
        rows_update(rlocation, by = "hid")
    }
    if (nrow(train.data) > N0) stop("Problem with 'rlocation'; merge led to erroneous increase in number of donor observations.")
    rm(rlocation, geo)
  }

  # Load donor variables to be fused
  cat("Loading fusion variables from", basename(dfile), "\n")
  idvars <- intersect(names(train.data), c('hid', 'pid'))
  dvars <- names(fst::fst(dfile))
  miss <- setdiff(fvars, dvars)
  if (length(miss)) stop("The following fusion variables are not present in the donor microdata:", paste(miss, collapse = ","), "\n")
  fuse.data <- fst::read_fst(dfile, as.data.table = TRUE, columns = c(idvars, fvars)) %>%
    setkeyv(idvars)

  # Load spatial predictors data
  cat("Loading spatial predictors from", basename(gfile), "\n")
  # Survey vintage (year); returns approximate midpoint year in case of range (e.g. "2014-2016" returns 2015)
  svintage <- ceiling(median(eval(parse(text = donor[2]))))
  spatial.data <- fst::read_fst(gfile, as.data.table = TRUE) %>%
    setkey(state, puma10) %>%   # TEMP -- remove 'vintage' as key in gfile
    filter(vintage == svintage) %>%
    select(-vintage)

  # Assemble full dataset needed for model training
  cat("Assembling full dataset for training\n")
  full.data <- train.data %>%
    merge(spatial.data, all.x = TRUE, sort = FALSE) %>%
    setkeyv(key(fuse.data)) %>%
    merge(fuse.data, all.x = TRUE, sort = FALSE) %>%
    select(-all_of(c(idvars, key(spatial.data)))) %>%
    select(weight, all_of(fvars), everything())

  rm(train.data, fuse.data)

  #-----

  # Load results of prepXY() with fusion and predictor variable details
  # cat("Loading prepXY() results:", basename(pfile), "\n")
  # prep <- readRDS(pfile)

  # NEW: If a 'fsn' object is provided, use those results to create 'prep' list instead of running prepXY()

  if (is.character(fsn)) {

    cat("\n|=== Existing .fsn model used to select predictors ===|\n\n")

    # Original harmonized predictors in training data of existing 'fsn' model
    hvars0 <- names(fst::fst(sub("_model.fsn", "_donor.fst", fsn, fixed = TRUE)))
    hvars0 <- grep("__", hvars0, fixed = TRUE, value = TRUE)

    # Variable importance results for existing 'fsn' model
    vimp <- fusionModel::importance(fsn)$detailed %>%
      distinct(y, x) %>%
      filter(x %in% names(full.data))
    if (!all(fvars %in% vimp$y)) stop("Not all 'fusion_vars' are present in the existing 'fsn' model")

    # Harmonized predictors in current training data that were not present for 'fsn' creation and, therefore, should always be included
    hvars <- grep("__", names(full.data), fixed = TRUE, value = TRUE)
    force <- setdiff(hvars, hvars0)

    # Extract metadata from 'fsn' and build associated 'prep' object
    fsn.files <- zip::zip_list(fsn)
    td <- tempfile()
    zip::unzip(zipfile = fsn, exdir = td)
    meta <- readRDS(file.path(td, "metadata.rds"))
    unlink(td)
    ylist <- lapply(meta$ylist, function(v) intersect(v, fvars))  # Restricts 'fsn' y-ordering to the requested fusion variables, in case only a subset of the 'fsn' fusion variables is requested
    ylist <- ylist[lengths(ylist) > 0]
    prep <- list(y = ylist)
    prep$x <- lapply(prep$y, function(v) {
      filter(vimp, y %in% v) %>%
        pull(x) %>%
        unique() %>%
        c(force)
    })

    xunique <- setdiff(unique(unlist(prep$x)), fvars)
    cat("Retained", length(xunique), "of", ncol(full.data) - length(fvars) - 1, "potential predictor variables\n")

  } else {

    cat("\n|=== Run fusionModel::prepXY() ===|\n\n")

    n0 <- nrow(full.data)
    pfrac <- min(1, ifelse(test_mode, 5e3, max(10e3, n0 * 0.1)) / n0)
    prep <- fusionModel::prepXY(data = full.data,
                                y = fusion_vars,
                                x = setdiff(names(full.data), c(fvars, "weight")),
                                weight = "weight",
                                cor_thresh = 0.025,
                                lasso_thresh = 0.975,
                                xmax = 100,
                                #xforce = xforce,
                                fraction = pfrac,
                                cores = ncores)

    # Save output from prepXY()
    xfile <- paste0(stub, "prep.rds")
    saveRDS(prep, file = xfile)
    cat("\nResults of prepXY() saved to:", paste0(basename(xfile), " (", fsize, " MB)"), "\n")

  }

  #---



  # Update 'full.data' to reflect results in 'prep'; removes unnecessary predictor variables
  full.data <- full.data %>%
    select(weight, any_of(unique(c(fvars, unlist(prep$x)))))

  #-----

  cat("\n|=== Run fusionModel::train() ===|\n\n")

  # LightGBM hyper-parameter settings
  hyper.params <- if (test_mode) {
    cat("Running in TEST mode using fast(er) hyper-parameter settings\n")
    list(
      boosting = "gbdt",
      data_sample_strategy = "goss",
      num_leaves = 7,
      min_data_in_leaf = max(20, ceiling(nrow(full.data) * 0.01)),
      num_iterations = 50,
      feature_fraction = 0.5,
      learning_rate = 0.2,
      max_depth = 3,
      max_bin = 255,
      min_data_in_bin = ceiling(nrow(full.data) * 0.01),
      max_cat_threshold = 32
    )
  } else {
    cat("Running in PRODUCTION mode using the following hyper-parameter settings:\n")
    hyper.params <- list(
      boosting = "gbdt",
      data_sample_strategy = "goss",
      num_leaves = 31,
      min_data_in_leaf = max(10, ceiling(nrow(full.data) * 0.001)),
      num_iterations = 2500,
      feature_fraction = 0.7,
      learning_rate = 0.1,
      max_depth = 5,
      max_bin = 255,
      min_data_in_bin = 3,
      max_cat_threshold = 32
    )
    print(hyper.params)
  }

  # Train fusion model
  cat("Training fusion model\n")
  fsn.path <- fusionModel::train(data = full.data,
                                 y = prep$y,
                                 x = prep$x,
                                 fsn = paste0(stub, "model.fsn"),
                                 weight = "weight",
                                 hyper = hyper.params,
                                 cores = ncores,
                                 ...)

  #-----

  # NEW: Extract variable importance
  # TO DO: Save results? Generate plot?
  # TO DO: Use the results to skip prepXY() step for other acs_year values
  #vimp <- fusionModel::importance(fsn.path)

  #-----

  # # (?) Update 'prep' object based on the importance results from initial training
  # #prep2 <- prep
  # for (yvar in prep$y) prep$x[[yvar]] <- filter(vimp$detailed, y == yvar, gain > 0.001)$x
  #
  # # TO DO: This will need to safely adjust for possibility that DIFFERENT harmonized variables are introduced for other acs_years -- these should be included by default for safety
  # attr(prep, "xpredictors") <- setdiff(names(full.data), c(fusion_vars, "weight"))

  #-----

  # If train() was forked, reset number of threads allowed in data.table and fst
  # if (fork) {
  #   data.table::setDTthreads(ncores)
  #   fst::threads_fst(ncores)
  # }

  #-----

  #if (validation | validation %in% 1:2) {
  if (validation) {

    cat("\n|=== Fuse onto donor microdata for internal validation ===|\n\n")

    # Fuse multiple implicates to training data for internal validation analysis
    validfsd <- fusionModel::fuse(data = full.data %>% select(-all_of(fvars)),
                                  fsn = fsn.path,
                                  M = M,
                                  fsd = paste0(stub, "valid.fsd"),
                                  cores = ncores)
  }

  #-----

  # # WORK ON THIS...
  # # TO DO: Skip this step for now??? Or run at very end using combined results from all acs_years?
  # if (validation | validation == 2) {
  #
  #   cat("\n|=== Run fusionModel::validate() ===|\n\n")
  #
  #   # Pass 'valid' implicates to validate() function
  #   validresults <- fusionModel::validate(observed = merge(train.data, spatial.data, all.x = TRUE),
  #                                         implicates = fusionModel::read_fsd(validfsd),
  #                                         subset_vars = attr(prep, "xforce"),
  #                                         weight = "weight",
  #                                         cores = ncores)
  #
  #   # Save 'validation' results as .rds
  #   vout <- paste0(stub, "validation.rds")
  #   saveRDS(validresults, file = vout)
  #   cat("Validation results saved to:\n", vout, "\n")
  #
  # }

  #-----

  cat("\n|=== Fuse onto recipient microdata ===|\n\n")

  # UPDATE
  # Remove unnecessary objects in memory prior to fuse()
  #suppressWarnings(rm(full.data, validfsd, validresults))

  # Load the prediction data and merge spatial predictors
  cat("Loading recipient microdata:", basename(pfile), "\n")
  predict.data <- fst::read_fst(pfile, as.data.table = TRUE) %>%
    merge(spatial.data, all.x = TRUE, sort = FALSE) %>%
    select(any_of(c(idvars, names(full.data)))) %>%
    setkeyv(idvars)

  # Fuse multiple implicates to ACS and save results to disk as compressed .csv
  cat("Fusing to ACS ", acs_year, " microdata (", M, " implicates)\n\n", sep = "")
  fusionModel::fuse(data = predict.data,
                    fsn = fsn.path,
                    M = M,
                    fsd = paste0(stub, "fused.fsd"),
                    retain = idvars,  # Retain the ACS household ID (and possible 'pid') in the output
                    cores = ncores)

  #-----

  # DEPRECATED
  # cat("\n|=== Upload /output files to Google Drive ===|\n\n")
  #
  # if (upload) {
  #   if (interactive()) {
  #     # Check if fusionData package is installed; it is necessary to call uploadFiles()
  #     fd <- !inherits(try(system.file(package='fusionData', mustWork = TRUE), silent = TRUE), "try-error")
  #     if (fd) {
  #       odf <- paste0(stub, c("model.fsn", "valid.fsd", "validation.rds", "fused.fsd"))
  #       odf <- odf[file.exists(odf)]  # Restrict to output files that exist
  #       uploadFiles(files = odf, ask = TRUE)
  #     } else {
  #       cat("fusionData package not installed; file upload skipped.\n")
  #     }
  #   } else {
  #     cat("Non-interactive session: skipping upload to Google Drive\n")
  #   }
  # } else {
  #   cat("'upload = FALSE'; file upload skipped at request of user.\n")
  # }

  #-----

  # Clean up and remove the temporary directory
  rm(predict.data, spatial.data)
  gc(verbose = FALSE)

  cat("\n|=== fusionOutput() is finished! ===|\n\n")

  # Report processing time
  tout <- difftime(Sys.time(), tstart)
  cat("Total processing time:", signif(as.numeric(tout), 3), attr(tout, "units"), "\n", sep = " ")

  # Finish logging and copy log file to /input
  log.path <- paste0(stub, "outputlog.txt")
  cat("\nLog file saved to:\n", log.path, "\n")
  sink(type = "output")
  close(log.txt)
  invisible(file.copy(from = log.temp, to = log.path, overwrite = TRUE))

  # Return the /output path invisibly
  return(invisible(dir))

}
